---
title: "Data 621 Homework 1: Moneyball"
author: "Critical Thinking Group 2 - Armenoush Aslanian-Persico, james Topor, Jeff Nieman, Scott Karr"
output:
  html_document:
    highlight: pygments
    keep_md: yes
    theme: cerulean
    toc: yes
  pdf_document: default
  word_document: default
---

```{r, eval=FALSE, include=FALSE, echo=FALSE}
BB.list <- read.csv("https://raw.githubusercontent.com/spsstudent15/2016-02-621-W1/master/moneyball-training-data.csv", header=TRUE,
    stringsAsFactors=FALSE, sep=",")
attach(BB.list)

# describe structure of dataset
str(BB.list)

# plot(BB.list[,3:17])

mb_cor <- cor(BB.list[,3:17])

round(mb_cor, 3)
```

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# library(knitr)
```
# Overview

In this homework assignment, you will explore, analyze and model a data set containing approximately 2200 records. Each record represents a professional baseball team from the years 1871 to 2006 inclusive. Each record has the performance of the team for the given year, with all of the statistics adjusted to match the performance of a 162 game season. 

Your objective is to build a multiple linear regression model on the training data to predict the number of wins for the team. You can only use the variables given to you (or variables that you derive from the variables
provided). Below is a short description of the variables of interest in the data set:

# Part 1. Data Exploration

## Data Summary 
The data base originally sent out has 17 attributes with 2277 lines.

Describe the size and the variables in the moneyball training data set. 
Mean / Standard Deviation / Median

## Data Plots
Bar Chart or Box Plot of the data

## Correlation Plot
Is the data correlated to the target variable (or to other variables?)

#Part 2 - Data Preparation:
## Missing and Invalid Data

We began by creating a new attribute for singles, taking the hits value and subtracting out the doubles, triples and home runs. Then we eliminated the batting hits column. We believe that separating out singles with the other unique hit values will minimize collinearity.

We followed by excluding 4 data attributes for the purpose of the models which we noticed during the data survey:

1. Hit by Pitch: In the case of hit by pitch there were very few values present (2085 missing). Based on SME knowledge from actual coaches we discovered that hit by pitches rarely impact wins. Therefore, we chose to exclude it.

2. Caught stealing: In the case of caught stealing there were many missing values as well (772). 
This attribute was found to be highly collinear with the stolen base attribute (because teams that steal a lot of bases will have more caught stealing). As a result, we chose to exclude this value and kept the positive value of stolen bases which had fewer missing components.

3. Pitching Home Runs Allowed: These data were also found to be highly collinear with batting homeruns as years with more homeruns hit directly match years with similar amount of homeruns allowed (for example, the years of "juicing" in the 1990's tended to have a lot of homeruns hit and therefore pitched, while the "dead ball years" prior to 1920 had very few hit and allowed). We chose to exclude this attribute and kept the home runs batting value. 

4. Index: These numbers were simply sorting keys and offer no real statistical value to the model and were therefore excluded. 

We then worked on imputing the remaining missing data. To do this we used a linear regression approach recommended by Faraway (p.201) and Fox (p.611). We decided against the using the mean or median as a replacement value for NA's since regression yields imputed values that are much more consistent with the actual distribution of the data while introducing much less bias than use of a mean or median would incur.

We built regression imputation models for the following variables. Each model was analyzed to ensure that there were no collinearity issues and all p-values were < $.05$:

1. __Batting strikeouts__: The adjusted R squared value for our regression was 0.7223 and the data appeared to be normally distributed. We created a function we called "impute" that allowed us to only replace the values missing with the imputed ones (and for batting strikeouts we imputed 102 values.

2. __Pitching strikeouts__: We achieved a very effective regression model here as the adjusted R squared value was 0.9952. Here again we imputed 102 values in the same rows as the batting strikeouts.

3. __Stolen Bases__: The model here was not quite as strong with an adjusted R squared value of 0.3427. Here we imputed 131 values.

4. __Double Plays__: The model here had an adjusted R squared value of 0.3904. Here we imputed 286 missing values. 

We completed data preparation for the training data set by eliminating some clearly egregious outliers based on research through baseball-almanac.com. This approach is suggested by Sheather (p. 57).  For exampe, the record for the most pitching strikeouts in a single season is 1450 by the 2014 Cleveland Indians. Therefore we know that any records having TEAM_PITCHING_SO values above that point is an aberration, and any records containing such values were summarily removed from the data set. 

Similarly, the most errors by team in a single season was 639 by Philadelphia in 1883. Prorating to 162 games we calculated that we should discard any records containing TEAM_FIELDING_E values above 1046. 

The TEAM_PITCHING_H variable also appeared to have numerous egregious outliers. For example, the most offensive hits by a team in a single season was 1730. As such, it is highly unlikely that any pitching staff would surrender more than 3000 hits in a single season since such a total would indicate the team was allowing more than 18 hits per game. As such, any records having a TEAM_PITCHING_H value > 3000 was removed from the data set.

Removing the egregious outliers resulting in a sum total of 104 records being removed from the training data set. Removal of these outliers helped to normalize our data and thereby improve the expected performance of our linear models.

# --- needs more editing below here

For our individual models we did look at combining certain fields or creating some unique attributes from the data fields provided. We also looked at power transformations as well. These model-based transformations will be covered in the individual model section.

## Addressing Outliers via Cook's Distance

A defensible approach, simplistic but valid is just deleting "bad" leverage points or invalid data and refitting the model w/o them. (Sheather MAR pg. 57). If you look at the Residuals vs Leverage plot (Sheather MAR pg. 70) is a good example, these points are outside of the +/- 2 SD --the so called Cook's distance and can be removed.  Its also in the flowchart on pg. 103.  The bonds example in the chapter 3 exercises of MAR have the Cook's Distance test code for the "Bond" example where he throws out 2 of 35 observations due to "bad" leverage.

Here's an extract . . .

Figure 3.13 on page 68
```{r}
#cd1 <- cooks.distance(m1)
#plot(CouponRate,cd1,xlab="Coupon Rate (%)", ylab="Cook's Distance")
#abline(h=4/(35-2),lty=2)
#identify(CouponRate,cd1,Case)
```


# -------------------------------------------------------

# Part 3. Build Models

## Model 1 - General Model Using Backward Selection

This model applies simple Backward Selection methods through the use of p-values and variance inflation factors (VIF) against the following predictor variables:

- TEAM_BATTING_1B (derived variable)  
- TEAM_BATTING_2B  
- TEAM_BATTING_3B  
- TEAM_BATTING_HR  
- TEAM_BATTING_BB  
- TEAM_BATTING_SO  
- TEAM_BASERUN_SB  
- TEAM_PITCHING_H  
- TEAM_PITCHING_BB  
- TEAM_PITCHING_SO  
- TEAM_FIELDING_E  
- TEAM_FIELDING_DP  

Simply removing the *TEAM_BATTING_1B* variable yielded a model with all p-values less than $.05$. However, VIF analysis showed evidence of multiple collinear variables within the model. Subsequent removals of *TEAM_PITCHING_SO* and *TEAM_PITCHING_BB* due to collinearity yielded a model that called for the removal of *TEAM_BATTING_2B* on the basis of its p-value.

The final model of that iteration of the linear modeling process showed clear evidence of a number of outliers as evidenced in R's summary diagnostic plots. Those outliers were removed via a series of additional iterations yielding the following final model, which varies from the inital iteration in that it includes *TEAM_BATTING_2B* due to the fact that removing the outliers improved the statistical significance of the variable :


| Coefficient   | Variable  
| ------------  | ------------
| 66.261        | Intercept 
| - 0.017       | TEAM_BATTING_2B
| + 0.150       | TEAM_BATTING_3B
| + 0.109       | TEAM_BATTING_HR
| + 0.022       | TEAM_BATTING_BB
| - 0.019       | TEAM_BATTING_SO
| + 0.065       | TEAM_BASERUN_SB
| + 0.016       | TEAM_PITCHING_H
| - 0.075       | TEAM_FIELDING_E
| - 0.109       | TEAM_FIELDING_DP  



| RSE   | R^2     | Adj. R^2  | F Stat. | MSE
| ----- | ------- | --------- | ------- | -----
| 11.49 | 0.3598  | 0.3572    | 134.4   | 132 

                     
However, the diagnostic plots of that model showed a lack of linearity between the response variable TARGET_WINS and the predictor variable TEAM_FIELDING_E as evidenced in the Added Variable plots shown in the Appendix. Furthermore, the plots of standardized residuals against each of the predictor variables showed evidence of non-constant variability for variables such as TEAM_BATTING_HR, TEAM_BATTING_SO, TEAM_BASERUN_SB, and TEAM_FIELDING_E.

The TEAM_FIELDING_E variable was subsequently transformed using a Box-Cox recommended power transform of (-1), or (1/y) and the model was re-run. The resulting Added Variable plots showed that all predictors are linearly related to the response, and we see an improvement in the variability of the residuals relative to TEAM_FIELDING_E. Furthermore, the plot of Y against the fitted values showed an improvement in the linearity of the model. 

Therefore, this model appears to be an improvement over the first model when the residual plots are considered. The characteristic equation indicated by the model is as follows:


| Coefficient   | Variable  
| ------------  | ------------
| 52.88         | Intercept 
| + 0.168       | TEAM_BATTING_3B
| + 0.096       | TEAM_BATTING_HR
| + 0.027       | TEAM_BATTING_BB
| - 0.027       | TEAM_BATTING_SO
| + 0.034       | TEAM_BASERUN_SB
| + 0.004       | TEAM_PITCHING_H
| + 3252.31     | 1/TEAM_FIELDING_E
| - 0.102       | TEAM_FIELDING_DP


| RSE   | R^2     | Adj. R^2  | F Stat. | MSE
| ----- | ------- | --------- | ------- | -----
| 11.86 | 0.3168  | 0.3143    | 124.8   | 141


The coefficients for TEAM_BATTING_3B, TEAM_BATTING_HR, TEAM_BATTING_BB, TEAM_BATTING_SO, and TEAM_BASERUN_SB all make sense intuitively. The TEAM_FIELDING_DP coefficient is less intuitive since one would expect more defensive double plays to improve a team's chances of winning games. However, the variable itself is *negatively* correlated with TARGET_WINS as shown in the __Data Exploration__ section above. As such, we shouldn't be surprised to see a negative coefficient for it here. Similarly, the coefficient for TEAM_PITCHING_H is also counterintuitive, but the variable is actually positively correlated with TARGET_WINS as shown in the __Data Exploration__ section. Finally, TEAM_FIELDING_E has changed from negative in the earlier model to positive here. However, this is due to the fact that the coefficient now applies to the *transformed* version of the variable rather than the nominal values of the variable.

While this model is an improvement over the initial model, we still have component variables that appear to lack constant variability relative to the residuals for variables such as TEAM_BASERUN_SB. The lack of constant variability in the residuals is likely related to the skewed nature of the distributions of those individual variables. 

In the other models discussed herein we attempt to address some of the skew issues via various methods, including Box-Cox recommended power transforms and linear combinations of various variables.


# -------------------------------------------------------

## Model 2 - Total Bases 

This model attempts to address some of the lack of constant variability found in the "General Model" discussed above by employing a linear combination of four of the predictor variables to calculate the baseball statistc known as "Total Bases". Total Bases is calculated using what our data set refers to as "TEAM_BATTING" variables as follows:

- Singles + (2 * Doubles) + (3 * Triples) = (4 * Home Runs)

Inclusion of this new variable allows us to eliminate the four component variables from the model. In fact, the TOTAL_BASES variable appears to be normally distributed, thereby negating the skew issues that were evident with its component variables.

```{r, echo = FALSE, warning=FALSE, message=FALSE}
# read clean data set from Github

mb_clean <- read.csv("https://raw.githubusercontent.com/spsstudent15/2016-02-621-W1/master/621-HW1-Clean-Data.csv")  

# create new variable and drop its components
mb_t <- mb_clean

mb_t$TB_ <- mb_clean$TEAM_BATTING_1B + (2 * mb_clean$TEAM_BATTING_2B) + 
                       (3 * mb_clean$TEAM_BATTING_3B) + (4 * mb_clean$TEAM_BATTING_HR)

par(mfrow = c(1,1))
hist(mb_t$TB, breaks = 200, main = "Distribution of TOTAL_BASES Variable", xlab = "TOTAL_BASES")

rm(mb_clean)
rm(mb_t)

```

This model applies simple Backward Selection methods through the use of p-values and variance inflation factors (VIF) against the following predictor variables:

- TEAM_TOTAL_BASES (derived variable)  
- TEAM_BATTING_BB  
- TEAM_BATTING_SO  
- TEAM_BASERUN_SB  
- TEAM_PITCHING_H  
- TEAM_PITCHING_BB  
- TEAM_PITCHING_SO  
- TEAM_FIELDING_E  
- TEAM_FIELDING_DP  

Three iterations of p-value / VIF backward selection removed TEAM_PITCHING_SO and TEAM_PITCHING_BB from the model. All other variables remained statistically significant with no signficant collinearity. However, evidence of multiple outliers was found via R's summary diagnostic plots. Those outliers were removed via a series of additional iterations yielding the following final model:


| Coefficient   | Variable  
| ------------  | ------------
| 48.486        | Intercept 
| + 0.022       | TEAM_BATTING_BB
| - 0.015       | TEAM_BATTING_SO
| + 0.063       | TEAM_BASERUN_SB
| + 0.010       | TEAM_PITCHING_H
| - 0.064       | TEAM_FIELDING_E
| - 0.117       | TEAM_FIELDING_DP
| + 0.018       | TOTAL_BASES


| RSE   | R^2     | Adj. R^2  | F Stat. | MSE
| ----- | ------- | --------- | ------- | -----
| 11.7  | 0.3365  | 0.3343    | 156     | 137


The diagnostic plots of that model show a lack of linearity between the response variable TARGET_WINS and the predictor variable TEAM_FIELDING_E as evidenced in the Added Variable plots shown in the Appendix. Furthermore, the plots of standardized residuals against each of the predictor variables showed evidence of non-constant variability for variables such as TEAM_BATTING_SO, TEAM_BASERUN_SB, and TEAM_FIELDING_E. 

The TEAM_FIELDING_E variable was subsequently transformed using a Box-Cox recommended power transform of (-1), or (1/y) and the model was re-run. The resulting Added Variable plots show that all predictors are linearly related to the response, and we see an improvement in the variability of the residuals relative to TEAM_FIELDING_E. Furthermore, the plot of Y against the fitted values shows an improvement in the linearity of the model. 

Therefore, this model appears to be an improvement over the first TOTAL_BASES model when the residual plots are considered. The characteristic equation indicated by the model is as follows:

| Coefficient   | Variable  
| ------------  | ------------
| 39.164        | Intercept 
| + 0.025       | TEAM_BATTING_BB
| - 0.025       | TEAM_BATTING_SO
| + 0.038       | TEAM_BASERUN_SB  
| + 2714.54     | 1/TEAM_FIELDING_E
| - 0.115       | TEAM_FIELDING_DP
| + 0.0197       | TOTAL_BASES


| RSE   | R^2     | Adj. R^2  | F Stat. | MSE
| ----- | ------- | --------- | ------- | -----
| 11.97 | 0.3048  | 0.3029    | 157.5   | 143




The coefficients for TEAM_BATTING_BB, TEAM_BATTING_SO, TEAM_BASERUN_SB, and TOTAL_BASES all make sense intuitively. The TEAM_FIELDING_DP coefficient is less intuitive since one would expect more defensive double plays to improve a team's chances of winning games. However, the variable itself is *negatively* correlated with TARGET_WINS as shown in the __Data Exploration__ section above. As such, we shouldn't be surprised to see a negative coefficient for it here. TEAM_FIELDING_E has changed from negative in the earlier model to positive here. However, this is due to the fact that the coefficient now applies to the *transformed* version of the variable rather than the nominal values of the variable.


# -------------------------------------------------------

## Model 3 - Total Bases PLUS

This model attempts to improve upon the results of the "Total Bases" model by extending the TOTAL_BASES variable to include the TEAM_BATTING_BB and TEAM_BASERUN_SB variables. The logic behind adding these two variables to the TOTAL_BASES variable comes from the fact that both, like the component variables of TOTAL_BASES, represent basepath advancements by a team's offense.

"Total Bases Plus"" (referred to as TB_PLUS hereon) is calculated using what our data set refers to as "TEAM_BATTING" and "TEAM_BASERUN" variables as follows:

- Singles + (2 * Doubles) + (3 * Triples) = (4 * Home Runs) + BB + SB  

Inclusion of this new variable allows us to eliminate the two additional component variables from the model. In fact, the TB_PLUS variable, like the TOTAL_BASES variable used earlier appears to be normally distributed, thereby negating the skew issues that were evident with its component variables. A histogram of the distribution of the derived TB_PLUS variable is shown below:


```{r, echo = FALSE, warning=FALSE, message=FALSE}
# read clean data set from Github

mb_clean <- read.csv("https://raw.githubusercontent.com/spsstudent15/2016-02-621-W1/master/621-HW1-Clean-Data.csv")  

# ---------------------------------------------------------------

# Build a model with Total Bases + SB + BB added and all of the other hitting vars removed

# create new variable and drop its components
mb_t <- mb_clean

mb_t$TB_PLUS <- mb_clean$TEAM_BATTING_1B + (2 * mb_clean$TEAM_BATTING_2B) + 
                       (3 * mb_clean$TEAM_BATTING_3B) + (4 * mb_clean$TEAM_BATTING_HR) + 
                       mb_clean$TEAM_BATTING_BB + mb_clean$TEAM_BASERUN_SB

par(mfrow = c(1,1))
hist(mb_t$TB_PLUS, breaks = 200, main = "Distribution of TB_PLUS Variable", xlab = "TB_PLUS")

rm(mb_clean)
rm(mb_t)

```

This model applies simple Backward Selection methods through the use of p-values and variance inflation factors (VIF) against the following predictor variables:

- TB_PLUS (derived variable)  
- TEAM_BATTING_SO  
- TEAM_PITCHING_H  
- TEAM_PITCHING_BB  
- TEAM_PITCHING_SO  
- TEAM_FIELDING_E  
- TEAM_FIELDING_DP  

Four iterations of p-value / VIF backward selection removed TEAM_PITCHING_H, TEAM_PITCHING_SO and TEAM_PITCHING_BB from the model. All other variables remained statistically significant with no signficant collinearity. However, evidence of multiple outliers was found via R's summary diagnostic plots. Those outliers were removed via a series of additional iterations yielding the following final model:


| Coefficient   | Variable  
| ------------  | ------------
| 52.330        | Intercept 
| - 0.016       | TEAM_BATTING_SO
| - 0.034       | TEAM_FIELDING_E
| - 0.154       | TEAM_FIELDING_DP
| + 0.025       | TB_PLUS


| RSE   | R^2     | Adj. R^2  | F Stat. | MSE
| ----- | ------- | --------- | ------- | -----
| 12.12 | 0.2944  | 0.2931    | 225.5   | 145



The coefficients for TEAM_BATTING_SO and TEAM_FIELDING_E make sense intuitively: the more strikeouts a team's offense has, the less likely it is to put the ball in play, and the more fielding errors a team commits, the more likely they are to lose games. The TEAM_FIELDING_DP coefficient is less intuitive since one would expect more defensive double plays to improve a team's chances of winning games. However, the variable itself is *negatively* correlated with TARGET_WINS as shown in the __Data Exploration__ section above. As such, we shouldn't be surprised to see a negative coefficient for it here. Finally, the coefficient for TB_PLUS is postively correlated with the response variable, which shouldn't surprise us since it encapsulates all of a team's offense hits, stolen bases, and bases on balls.

As with the "General Model" and the "Total Bases" model, the diagnostic plots for this model showed a lack of linearity between the response variable TARGET_WINS and the predictor variable TEAM_FIELDING_E as evidenced in the Added Variable plots shown in the Appendix. Furthermore, the plots of standardized residuals against each of the predictor variables showed evidence of non-constant variability for the variables TEAM_BATTING_SO and TEAM_FIELDING_E.

The TEAM_FIELDING_E variable was subsequently transformed using a Box-Cox recommended power transform of (-1), or (1/y) and the model was re-run. The resulting Added Variable plots showed that all predictors are linearly related to the response, and we found an improvement in the variability of the residuals relative to TEAM_FIELDING_E. Furthermore, the plot of Y against the fitted values shows a non-skewed linear relationship. 

Therefore, this model appears to be an improvement over the first TB_PLUS model when the residual plots are considered. Furthermore, the number of predictor variables used here is two fewer than that of the "Total Bases" model discussed earlier. The characteristic equation indicated by the model is as follows:

                     
| Coefficient   | Variable  
| ------------  | ------------
| 42.160        | Intercept 
| - 0.023       | TEAM_BATTING_SO
| + 2366.82     | 1/TEAM_FIELDING_E
| - 0.140       | TEAM_FIELDING_DP
| + 0.022       | TB_PLUS


| RSE   | R^2     | Adj. R^2  | F Stat. | MSE
| ----- | ------- | --------- | ------- | -----
| 12.13 | 0.2932  | 0.2919    | 223.3   | 147


As we can see, the coefficient for TEAM_FIELDING_E has changed from negative to positive. However, this is due to the fact that the coefficient now applies to the *transformed* version of the variable rather than the nominal values of the variable. The other coefficients remain the same.

# -------------------------------------------------------

## Model 4 :Sabermetrics Model

Sabermetrics has become the rage in baseball, actually popularized by Billy Beane and the data set we are exploring.  As a result of this, we built a model that centers around one of these advance analyticsm known as BsR or base runs. This statistic was designed by David Smyth in the 1990's and estimates the amount of runs a team SHOULD score, which made a unique approach as the data set provided did not include runs (see http://tangotiger.net/wiki_archive/Base_Runs.html for more information). The formula is as follows:  

BSR = A*B/(B+C) +D where:  

- A = TEAM_BATTING_1B + TEAM_BATTING_2B + TEAM_BATTING_3B + TEAM_BATTING_BB  

- B = 1.02*(1.4*TEAM_TOTAL_BASES -0.6*TEAM_BATTING_H + 0.1*TEAM_BATTING_BB)  

- C = AT BATS - TEAM_BATTING_H (which we approximated with 3*TEAM_BATTING_H as the average batting average is around 0.250)  

- D = TEAM_BATTING_HR  
    
Since we eliminated the value of TEAM_BATTING_H we simply summed up singles, doubles, triples and home runs in the actual code, and the approach for TEAM_TOTAL_BASES is described in model 2.  The data for BSR exhibit a fairly normal distribution.

- __Insert BSR histogram here??__

Since BSR is a combination of all of the batting variables, we simply eliminated them and created a very strong model on the first iteration.  All p-values were very low, and the variation are all below 5 showing no probems with collinearity.  The characteristic equation indicated by the model is as follows:


| Coefficient   | Variable  
| ------------  | ------------
| 40.689953     | Intercept 
| + 0.062185    | BSR
| - 0.116618    | TEAM_FIELDING_DP
| - 0.058867    | TEAM_FIELDING_E
| + 0.60318     | TEAM_BASERUN_SB
| - 0.011451    | TEAM_PITCHING_SO
| + 0.019421    | TEAM_PITCHING_H
| - 0.017615    | TEAM_PITCHING_BB


| RSE   | R^2     | Adj. R^2  | F Stat. | MSE
| ----- | ------- | --------- | ------- | -----
| 11.99 | 0.3229  | 0.3207    | 147.4   | 144



The coefficients for this model overall make sense with one exception.  Errors and pitching walks contribute to fewer wins, and stolen bases and the BSR metric have strong influence on increasing wins.  Double plays do habve a slightly negative value, although this could be explained by a team allowing a large number of baserunners.     The positive impact of allowing pitching hits was puzzling.


# -------------------------------------------------------

## Model 5


- INSERT WRITEUP HERE

Placeholder tables - need to be filled in with ACTUAL metrics for Model 5

| Coefficient   | Variable  
| ------------  | ------------
| 52.88         | Intercept 
| + 0.168       | TEAM_BATTING_3B
| + 0.096       | TEAM_BATTING_HR
| + 0.027       | TEAM_BATTING_BB
| - 0.027       | TEAM_BATTING_SO
| + 0.034       | TEAM_BASERUN_SB
| + 0.004       | TEAM_PITCHING_H
| + 3252.31     | 1/TEAM_FIELDING_E
| - 0.102       | TEAM_FIELDING_DP


| RSE   | R^2     | Adj. R^2  | F Stat. | MSE
| ----- | ------- | --------- | ------- | -----
| 11.86 | 0.3168  | 0.3143    | 124.8   | 141

# -------------------------------------------------------

# Part 4. Select Models

The chart below summarizes the model statistics for all five of our models:


| Metric    | General Model | Total Bases | TB PLUS | Sabermetrics  | Model 5  
| --------- | ------------- | ----------- | ------- | ------------- | -------  
| RSE       | 11.86         | 11.97       | 12.12   | 11.99         | 0 
| R^2       | 0.3168        | 0.3048      | 0.2994  | 0.3229        | 0
| Adj. R^2  | 0.3143        | 0.3029      | 0.2931  | 0.3207        | 0
| F Stat.   | 124.8         | 157.5       | 224.3   | 147.4         | 0 
| MSE       | 141           | 143         | 147     | 144           | 0 


As we compared our models, it was clear that the two strongest were the TB_PLUS model (#3) and the sabermetrics model (#4).  Models 1 and 2 were rejected for reasons explained in their respective model descriptions.

Our analysis showed that both model #3 and model #4 seem to have no issues with collinearity.  As the table shows, the decision is not immediately obvious based solely on the model's statistcs, as the sabermetrics model had the better R^2 and RSE values, while the Total Bases model had the better F statistic.  

While both models obviously reject the null hypothesis, the TB_PLUS model has a much larger F-Statistic value which shows that it is explaining more of the variability of the training data than is the Sabermetrics model. Furthermore, the TB_PLUS model is simpler in that it makes use of only 4 predictor variables and yields favorable diagnostic plots.

  
  
  
To test our models, we needed an evaluation data set with NA's imputed. We checked the imputation output to ensure it conformed with the actual distribution of each of the impacted variables in the EVAL set. 

The EVAL data set with the NA's filled can be found here:

<a href="https://raw.githubusercontent.com/spsstudent15/2016-02-621-W1/master/621-HW1-Clean-EvalData-.csv">Clean Eval Data</a>

```{r}

```
